{"metadata": {"language_info": {"pygments_lexer": "ipython3", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "version": "3.6.3", "file_extension": ".py", "nbconvert_exporter": "python"}, "anaconda-cloud": {}, "kernelspec": {"name": "python3", "display_name": "Python [default]", "language": "python"}}, "nbformat": 4, "cells": [{"metadata": {}, "cell_type": "markdown", "source": ["# Prestack seismic\n", "\n", "**[Smaller single gather file on S3/agilegeo (3.8GB)](https://s3.amazonaws.com/agilegeo/3D_gathers_pstm_nmo_X1001.sgy)**\n", "\n", "**[Larger gathers files on Open Seismic Repository (ca. 10GB)](https://opendtect.org/osr/pmwiki.php/Main/PENOBSCOT3DSABLEISLAND)**\n", "\n", "For now we'll satisfy ourselves with reading some prestack seismic data from disk, and looking at it.\n", "\n", "Eventually we can:\n", "\n", "- Extract prestack attributes from the gathers.\n", "- Examine a well from one of the gather locations.\n", "- Model the AVO behaviour at the well and compare to the prestack data."]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Read the SEGY file\n", "\n", "This is a large file \u2014\u00a0and this is only 1 of 30 or so files in this ca. 90GB dataset \u2013 so we will use `headonly=True` to only parse the headers with `_read_segy()`, then we can index into the stream as before. The difference is that this time, the data stays on disk until we do that read."]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["filename = '../data/3D_gathers_pstm_nmo_X1001.sgy'"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from obspy.io.segy.segy import _read_segy\n", "\n", "# Only read the headers, otherwise you will get memory issues\n", "stream = _read_segy(filename, headonly=True)"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["stream"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["x = np.array(list(stream.textual_file_header.decode()))\n", "print('\\n'.join(''.join(row) for row in x.reshape((40, 80))))"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Organize the data"]}, {"metadata": {}, "cell_type": "markdown", "source": ["This is where we get the data from disk. We'll just grab a bit. There are about 22 traces per gather, so we'll go for 100-ish gathers.\n", "\n", "The tricky thing with this dataset is that there are a variable number of traces per gather, so we can't just read it like a regular 3D."]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["traces_to_read = 2200\n", "data = np.vstack([t.data for t in stream.traces[:traces_to_read]])\n", "gno = np.array([t.header.trace_number_within_the_ensemble for t in stream.traces[:traces_to_read]])"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# We'll need the number of time samples.\n", "_, t = data.shape"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# Find the max number of traces in a gather.\n", "values, counts = np.unique(gno, return_counts=True)"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# Collect all the traces according to the trace header no.\n", "gathers = np.vstack([data[gno==i] for i in values])"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# Make a mask, False where there's no trace for that gather.\n", "mask = np.arange(np.amax(counts)) < counts[:, None]\n", "\n", "# We have to mask with a 1D array so make the out one row per trace.\n", "out = np.zeros((mask.size, t))\n", "out[np.ravel(mask)] = gathers"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["lines, traces = mask.shape\n", "\n", "# Reshape back to the 3D geometry.\n", "g3 = out.reshape(lines, traces, t)"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["plt.figure(figsize=(3,14))\n", "plt.imshow(g3[68].T, cmap='Greys', aspect='auto')\n", "plt.show()"]}, {"metadata": {}, "cell_type": "markdown", "source": ["The stack is formed by averaging these traces, usually a swath of angles. So fewer traces contribute near the top; more at the bottom. The complete stack would look like this:"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["idx = np.arange(0, g3.shape[-1])\n", "perc = np.percentile(g3, 95)\n", "\n", "plt.figure(figsize=(8,20))\n", "plt.imshow(g3[67].T, cmap='Greys', aspect=.1)\n", "plt.plot(np.mean(g3[67], axis=0)/perc, idx)\n", "plt.ylim(400, 0)\n", "plt.show()"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Make an angle stack\n", "\n", "We'll pretend there's a constant velocity of 2000 m/s to make life easier. Then 1 ms corresponds to 1 m, so with a sample interval of 4 ms, we're looking at 4 m samples in depth.\n", "\n", "In the header, it says this:\n", "\n", "    output offset pannels  175m - 3175m with bin size 50m   \n", "    \n", "I don't totally understand the bin size remark. We have 22 traces, we'll assume the near trace is 175 m offset, and the far is 3175 m.\n", "\n", "$$ \\tan \\theta = \\frac{x}{d} \\ \\ \\mathrm{so} \\ \\ d = \\frac{x}{\\tan \\theta} $$"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["theta = np.radians(30)\n", "d = 4*idx / np.tan(theta)\n", "\n", "# We need the index.\n", "incr = 3175 / 22\n", "d_i = 1 + (d // incr).astype(int)\n", "d_i[d_i >= 22] = 22"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["d_i[:40]"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["plt.figure(figsize=(6,14))\n", "plt.imshow(g3[68].T, cmap='Greys', interpolation='none', aspect='auto')\n", "plt.plot(d_i, idx)\n", "plt.ylim(1000, 0)\n", "plt.show()"]}, {"metadata": {}, "cell_type": "markdown", "source": ["We'll apply that as a mute. We'll make `NaN`s so we can easily drop them out of the mean."]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# Bah, there has to be a more elegant way...\n", "for gather in g3:\n", "    for row, i in zip(gather.T, d_i):\n", "        row[i:] = np.nan"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["plt.figure(figsize=(6,14))\n", "plt.imshow(g3[68].T, cmap='Greys', interpolation='none', aspect='auto')\n", "plt.plot(d_i, idx)\n", "plt.ylim(1000, 0)\n", "plt.show()"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Make a stacked section"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["plt.figure(figsize=(16,16))\n", "plt.imshow(np.nanmean(g3.T, axis=1), cmap='Greys', vmin=-perc, vmax=perc, interpolation='none', aspect='auto')\n", "plt.show()"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## The power of stack"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Remember, one of the points of stacking is noise reduction. Let's look at a really noisy trace and see what happens when we stack it. We'll use the mean trace from before:"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["tr = np.nanmean(g3[68], axis=0)/perc"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["panel = np.repeat(tr, 50).reshape(tr.size, 50)"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["panel += np.random.random(panel.shape) * np.ptp(panel) - np.ptp(panel)/2"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["plt.figure(figsize=(16,8))\n", "plt.imshow(panel, cmap=\"Greys\", interpolation='none', aspect='auto')\n", "plt.show()"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["plt.figure(figsize=(16,2))\n", "plt.plot(tr)\n", "plt.plot(np.nanmean(panel, axis=1))\n", "plt.show()"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["plt.figure(figsize=(16,2))\n", "plt.plot(tr[600:800])\n", "plt.plot(np.nanmean(panel, axis=1)[600:800])\n", "plt.show()"]}, {"metadata": {}, "cell_type": "markdown", "source": ["<hr />\n", "\n", "<div>\n", "<img src=\"https://avatars1.githubusercontent.com/u/1692321?s=50\"><p style=\"text-align:center\">\u00a9 Agile Geoscience 2016</p>\n", "</div>"]}], "nbformat_minor": 1}