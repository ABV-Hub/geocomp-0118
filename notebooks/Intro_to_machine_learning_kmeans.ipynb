{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "name": "python", "version": "3.5.4"}, "anaconda-cloud": {}}, "nbformat": 4, "cells": [{"metadata": {}, "cell_type": "markdown", "source": ["# Intro to machine learning - k-means\n", "---\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Scikit-learn has a nice set of unsupervised learning routines which can be used to explore clustering in the parameter space.\n", "\n", "In this notebook we will use k-means, included in Scikit-learn, to demonstrate how the different rocks occupy different regions in the available parameter space.\n", "\n", "Let's load the data using pandas:"]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["import pandas as pd\n", "import numpy as np"], "execution_count": null}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df = pd.read_csv(\"../data/2016_ML_contest_training_data.csv\")\n", "df.head()"], "execution_count": null}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df.describe()"], "execution_count": null}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df = df.dropna()"], "execution_count": null}, {"metadata": {}, "cell_type": "markdown", "source": ["## Calculate RHOB from DeltaPHI and PHIND"]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["def rhob(phi_rhob, Rho_matrix= 2650.0, Rho_fluid=1000.0):\n", "    \"\"\"\n", "    Rho_matrix (sandstone) : 2.65 g/cc\n", "    Rho_matrix (Limestome): 2.71 g/cc\n", "    Rho_matrix (Dolomite): 2.876 g/cc\n", "    Rho_matrix (Anyhydrite): 2.977 g/cc\n", "    Rho_matrix (Salt): 2.032 g/cc\n", "\n", "    Rho_fluid (fresh water): 1.0 g/cc (is this more mud-like?)\n", "    Rho_fluid (salt water): 1.1 g/cc\n", "    see wiki.aapg.org/Density-neutron_log_porosity\n", "    returns density porosity log \"\"\"\n", "    \n", "    return Rho_matrix*(1 - phi_rhob) + Rho_fluid*phi_rhob\n"], "execution_count": null}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["phi_rhob = 2*(df.PHIND/100)/(1 - df.DeltaPHI/100) - df.DeltaPHI/100\n", "calc_RHOB = rhob(phi_rhob)\n", "df['RHOB'] = calc_RHOB"], "execution_count": null}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df.describe()"], "execution_count": null}, {"metadata": {}, "cell_type": "markdown", "source": ["We can define a Python dictionary to relate facies with the integer label on the `DataFrame`"]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["facies_dict = {1:'sandstone', 2:'c_siltstone', 3:'f_siltstone', 4:'marine_silt_shale',\n", "               5:'mudstone', 6:'wackentstone', 7:'dolomite', 8:'packstone', 9:'bafflestone'}"], "execution_count": null}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df[\"s_Facies\"] = df.Facies.map(lambda x: facies_dict[x])"], "execution_count": null}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df.head()"], "execution_count": null}, {"metadata": {}, "cell_type": "markdown", "source": ["We can easily visualize the properties of each facies and how they compare using a `PairPlot`. The library `seaborn` integrates with matplotlib to make these kind of plots easily."]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "g = sns.PairGrid(df, hue=\"s_Facies\", vars=['GR','RHOB','PE','ILD_log10'], size=4)\n", "\n", "g.map_upper(plt.scatter,**dict(alpha=0.4))  \n", "g.map_lower(plt.scatter,**dict(alpha=0.4))\n", "g.map_diag(plt.hist,**dict(bins=20))  \n", "g.add_legend()\n", "g.set(alpha=0.5)"], "execution_count": null}, {"metadata": {}, "cell_type": "markdown", "source": ["It is very clear that it's hard to separate these facies in feature space. Let's just select a couple of facies and using Pandas, select the rows in the `DataFrame` that contain information about those facies "]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["selected = ['f_siltstone', 'bafflestone', 'wackentstone']\n", "\n", "dfs = pd.concat(list(map(lambda x: df[df.s_Facies == x], selected)))\n", "\n", "g = sns.PairGrid(dfs, hue=\"s_Facies\", vars=['GR','RHOB','PE','ILD_log10'], size=4)  \n", "g.map_upper(plt.scatter,**dict(alpha=0.4))  \n", "g.map_lower(plt.scatter,**dict(alpha=0.4))\n", "g.map_diag(plt.hist,**dict(bins=20))  \n", "g.add_legend()\n", "g.set(alpha=0.5)"], "execution_count": null}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# Make X and y\n", "X = dfs[['GR','ILD_log10','PE']].as_matrix()\n", "y = dfs['Facies'].values"], "execution_count": null}, {"metadata": {}, "cell_type": "markdown", "source": ["Use scikit-learn StandardScaler to normalize the data. Needed for k-means."]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["from sklearn.preprocessing import StandardScaler\n", "\n", "scaler = StandardScaler()\n", "X = scaler.fit_transform(X)"], "execution_count": null}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.3)"], "execution_count": null}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["from sklearn.cluster import KMeans\n", "\n", "clf = KMeans(n_clusters=4, random_state=1).fit(X)\n", "y_pred = clf.predict(X)\n", "\n", "plt.scatter(X[:, 0], X[:, 1], c=y_pred, alpha=0.3)"], "execution_count": null}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["clf.inertia_"], "execution_count": null}, {"metadata": {}, "cell_type": "markdown", "source": ["<hr />\n", "\n", "<p style=\"color:gray\">\u00a92017 Agile Geoscience. Licensed CC-BY.</p>"]}], "nbformat_minor": 2}