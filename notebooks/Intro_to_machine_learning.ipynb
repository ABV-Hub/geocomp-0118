{"metadata": {"language_info": {"pygments_lexer": "ipython3", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "version": "3.5.2", "file_extension": ".py", "nbconvert_exporter": "python"}, "kernelspec": {"name": "python3", "display_name": "Python [default]", "language": "python"}}, "nbformat": 4, "cells": [{"metadata": {}, "cell_type": "markdown", "source": ["# Intro to machine learning"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import numpy as np\n", "import matplotlib.pyplot as mpl\n", "% matplotlib inline\n", "\n", "import sklearn as sk\n", "sk.__version__"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Read the data\n", "\n", "`numpy` has a convenient function, `loadtxt` that can load a CSV file. It needs a file... and ours is on the web. That's OK, we don't need to download it, we can just read it by sending its text content to a `StringIO` object, which acts exactly like a file handle."]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import requests\n", "import io\n", "\n", "r = requests.get('https://raw.githubusercontent.com/seg/2016-ml-contest/master/training_data.csv')\n", "f = io.StringIO(r.text)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["We can't just load it, because we only want NumPy to have to handle an array of floats and there's metadata in this file (we cna't tell that, I just happen to know it... and it's normal for CSV files). \n", "\n", "Let's look at the first few rows:"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["r.text.split('\\n')[:5]"]}, {"metadata": {}, "cell_type": "markdown", "source": ["For convenience later, we'll make a list of the features we're going to use."]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["features = r.text.split('\\n')[0].split(',')\n", "_ = [features.pop(i) for i in reversed([0,1,2])]\n", "features"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Now we'll load the data we want. First the feature vectors, `X`..."]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["X = np.loadtxt(f, skiprows=1, delimiter=',', usecols=[3,4,5,6,7,8,9,10])"]}, {"metadata": {}, "cell_type": "markdown", "source": ["And the label vector, `y`:"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["_ = f.seek(0)  # Reset the file reader.\n", "y = np.loadtxt(f, skiprows=1, delimiter=',', usecols=[0])"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["X.shape, y.shape"]}, {"metadata": {}, "cell_type": "markdown", "source": ["We have data! Almost ready to train, we just have to get our test / train subsets sorted.\n", "\n", "## Getting ready to train"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn.model_selection import train_test_split"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["X_train.shape, y_train.shape"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Now the fun can really begin. \n", "\n", "## Training and evaluating a model"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn.ensemble import ExtraTreesClassifier "]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["clf = ExtraTreesClassifier()"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["clf.fit(X_train, y_train)"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["clf.score(X_test, y_test)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Maybe we can do better by twiddling some of those parameters:"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["clf = ExtraTreesClassifier(n_estimators=2000, n_jobs=4, verbose=1)\n", "clf.fit(X_train, y_train)\n", "clf.score(X_test, y_test)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["All models have the same API (but not the same hyperparameters), so it's very easy to try lots of models:"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn.neighbors import KNeighborsClassifier\n", "KNeighborsClassifier().fit(X_train, y_train).score(X_test, y_test)"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn.svm import SVC\n", "SVC().fit(X_train, y_train).score(X_test, y_test)"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn.naive_bayes import GaussianNB\n", "GaussianNB().fit(X_train, y_train).score(X_test, y_test)"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn.ensemble import GradientBoostingClassifier\n", "GradientBoostingClassifier().fit(X_train, y_train).score(X_test, y_test)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## More in-depth evaluation: k-fold cross-validation\n", "\n", "We need a vector that contains an integer (or something) representing each unique well."]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["wells = [row.split(',')[2] for row in r.text.split('\\n')[1:] if row]"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn.model_selection import LeaveOneGroupOut\n", "\n", "logo = LeaveOneGroupOut()\n", "clf = ExtraTreesClassifier(random_state=0)\n", "\n", "for train, test in logo.split(X, y, groups=wells):\n", "    # train and test are the indices of the data to use.\n", "    well_name = wells[test[0]]\n", "    clf.fit(X[train], y[train])\n", "    score = clf.score(X[test], y[test])\n", "    print(\"{:>20s}  {:.3f}\".format(well_name, score))"]}, {"metadata": {}, "cell_type": "markdown", "source": ["<hr />\n", "\n", "<div>\n", "<img src=\"https://avatars1.githubusercontent.com/u/1692321?s=50\"><p style=\"text-align:center\">\u00a9 Agile Geoscience 2016</p>\n", "</div>"]}], "nbformat_minor": 0}