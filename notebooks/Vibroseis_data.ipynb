{"nbformat": 4, "nbformat_minor": 1, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python [default]", "language": "python"}, "language_info": {"name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "version": "3.6.3", "mimetype": "text/x-python", "nbconvert_exporter": "python", "file_extension": ".py"}, "anaconda-cloud": {}}, "cells": [{"source": ["# Vibroseis data\n", "\n", "**[Download the data from source](http://www.geofizyka.pl/2D_Land_vibro_data_2ms.tgz) or from [Agile's S3 bucket](\t\n", "https://s3.amazonaws.com/agilegeo/2D_Land_vibro_data_2ms.tgz).**\n", "\n", "This prestack 2D land Vibroseis dataset was donated to the public domain by [Geofizyka Torun, Poland](http://www.geofizyka.pl/).\n", "\n", "More info about this line:\n", "\n", "- Info about this line [on SEG Wiki](http://wiki.seg.org/wiki/2D_Vibroseis_Line_001). \n", "- A [Madagascar tutorial](http://ahay.org/wikilocal/docs/school10.pdf) using this line, by Yang Liu.\n", "- A [FreeUSP tutorial](http://www.freeusp.org/RaceCarWebsite/TechTransfer/Tutorials/Processing_2D/Processing_2D.html) using this line, by Paul Garossino."], "cell_type": "markdown", "metadata": {}}, {"source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["import obspy\n", "obspy.__version__"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["ls -l ../data/poland"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["We'll use this helper function later."], "cell_type": "markdown", "metadata": {}}, {"source": ["def view_header(string, width=80):\n", "    try:\n", "        # Make sure we don't have a ``bytes`` object.\n", "        string = string.decode()\n", "    except:\n", "        # String is already a string, carry on.\n", "        pass\n", "    lines = int(np.ceil(len(string) / width))\n", "    result = ''\n", "    for i in range(lines):\n", "        line = string[i*width:i*width+width]\n", "        result += line + (width-len(line))*' ' + '\\n'\n", "    print(result)\n", "    return"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["## Load data"], "cell_type": "markdown", "metadata": {}}, {"source": ["filename = '../data/poland/Line_001.sgy'"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["from obspy.io.segy.segy import _read_segy\n", "section = _read_segy(filename)"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["The file-wide header:"], "cell_type": "markdown", "metadata": {}}, {"source": ["view_header(section.textual_file_header)"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["The import line is this:\n", "\n", "    C 5 DATA TRACES/RECORD: 282  AUXILIARY TRACES/RECORD:  2    CDP FOLD            \n", "\n", "There are 282 data traces, plus 2 auxilliary traces, so a total of **284 traces in each record**.\n", "\n", "Let's also check a trace header:"], "cell_type": "markdown", "metadata": {}}, {"source": ["section.traces[3].header"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["There's also a readme file:"], "cell_type": "markdown", "metadata": {}}, {"source": ["!cat ../data/poland/Line_001.TXT"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["This might be useful, but remember not to believe anything you read."], "cell_type": "markdown", "metadata": {}}, {"source": ["## Explore and organize the data\n", "\n", "First we'll collect the traces and reshape them into a volume."], "cell_type": "markdown", "metadata": {}}, {"source": ["raw = np.vstack([t.data for t in section.traces])"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["raw.shape"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["First 1000 traces:"], "cell_type": "markdown", "metadata": {}}, {"source": ["plt.figure(figsize=(18,8))\n", "plt.imshow(raw[:1000, :].T, cmap=\"Greys\", vmin=-.1, vmax=.1, aspect=0.25, interpolation='none')\n", "plt.colorbar(shrink=0.5)\n", "plt.show()"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["Recall that there are 284 traces (282 + 2 auxilliary) per ensemble, we can use the `reshape` trick of passing `-1` as one of the dimensions to get it to compute that axis on the fly, given the other two dimensions. We'll pass the last dimension of the input data to avoid changing the shape in that dimension. "], "cell_type": "markdown", "metadata": {}}, {"source": ["data = raw.reshape((-1, 284, raw.shape[-1]))"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["plt.figure(figsize=(18,8))\n", "plt.imshow(data[90, :, :].T, cmap=\"Greys\", vmin=-1, vmax=1, aspect=0.1, interpolation='none')\n", "plt.colorbar(shrink=0.5)\n", "plt.show()"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["There are two special data traces at the start of each ensemble. Let's pull those out so we have 'pure' gathers."], "cell_type": "markdown", "metadata": {}}, {"source": ["gathers = data[:, 2:, :]\n", "\n", "vm = np.percentile(gathers, 99)\n", "\n", "plt.figure(figsize=(18,8))\n", "plt.imshow(gathers[0, :, :].T, cmap=\"Greys\", vmin=-vm, vmax=vm, aspect=0.1, interpolation='none')\n", "plt.colorbar(shrink=0.5)\n", "plt.show()"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["Let's go back and look at that zeroth trace \u2014\u00a0we'll just look at the one on the 91st gather:"], "cell_type": "markdown", "metadata": {}}, {"source": ["t90 = data[0,:,:]"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["plt.figure(figsize=(16,3))\n", "plt.plot(t90[0,:])\n", "plt.show()"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["#np.savetxt(\"../data/poland_wavelet.txt\", t90[0,:])"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["## Source and receiver positions\n", "\n", "Let's look at the source and receiver data."], "cell_type": "markdown", "metadata": {}}, {"source": ["!head -25 ../data/poland/Line_001.RPS"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["The obvious way to load this sort of data is `pandas`..."], "cell_type": "markdown", "metadata": {}}, {"source": ["names = ['Record', 'Point', 'Static', 'Easting', 'Northing', 'Elevation']\n", "cols = [0, 1, 2, 7, 8, 9]"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["import pandas\n", "\n", "rcv = pandas.read_csv('../data/poland/Line_001.RPS',\n", "                      delim_whitespace=True,\n", "                      skiprows=20,\n", "                      usecols=cols,\n", "                      names=names,\n", "                     )"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["rcv.head()"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["rcv.describe()"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["Hopefully the source data is the same..."], "cell_type": "markdown", "metadata": {}}, {"source": ["!head -25 ../data/poland/Line_001.SPS"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["It is!"], "cell_type": "markdown", "metadata": {}}, {"source": ["src = pandas.read_csv('../data/poland/Line_001.SPS',\n", "                      delim_whitespace=True,\n", "                      skiprows=20,\n", "                      usecols=cols,\n", "                      names=names,\n", "                     )"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["src.head()"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["Now plot them together."], "cell_type": "markdown", "metadata": {}}, {"source": ["plt.scatter(src.Easting, src.Northing, c='r', lw=0, s=3, alpha=0.5, label='src')\n", "plt.scatter(rcv.Easting, rcv.Northing, c='b', lw=0, s=2, alpha=0.4, label='rcv')\n", "plt.legend(loc=2)\n", "plt.show()"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["!head -25 ../data/poland/Line_001.XPS"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["## Brute stack\n", "\n", "We can stack the traces as they are, without any noise suppression, NMO correction, etc."], "cell_type": "markdown", "metadata": {}}, {"source": ["gathers.shape"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["brute = np.mean(gathers, axis=1)"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["vm = np.percentile(brute, 99)"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["plt.figure(figsize=(18,8))\n", "plt.imshow(brute.T, cmap=\"Greys\", vmin=-vm, vmax=vm, aspect=0.1, interpolation='none')\n", "plt.colorbar(shrink=0.5)\n", "plt.show()"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["### Write this out to SEG-Y"], "cell_type": "markdown", "metadata": {}}, {"source": ["from obspy.core import Trace, Stream, UTCDateTime\n", "from obspy.io.segy.segy import SEGYTraceHeader\n", "\n", "stream = Stream()\n", "\n", "for i, trace in enumerate(brute):\n", "\n", "    # Make the trace.\n", "    tr = Trace(trace)\n", "\n", "    # Add required data.\n", "    tr.stats.delta = 0.004\n", "    tr.stats.starttime = 0  # Not strictly required.\n", "\n", "    # Add yet more to the header (optional).\n", "    tr.stats.segy = {'trace_header': SEGYTraceHeader()}\n", "    tr.stats.segy.trace_header.trace_sequence_number_within_line = i + 1\n", "    tr.stats.segy.trace_header.receiver_group_elevation = 0\n", "\n", "    # Append the trace to the stream.\n", "    stream.append(tr)\n", "    \n", "from obspy.core import AttribDict\n", "from obspy.io.segy.segy import SEGYBinaryFileHeader\n", "\n", "# Text header.\n", "stream.stats = AttribDict()\n", "stream.stats.textual_file_header = '{:80s}'.format('This is the textual header.').encode()\n", "stream.stats.textual_file_header += '{:80s}'.format('This file contains a brute stack.').encode()\n", "stream.stats.textual_file_header += '{:80s}'.format('The original file header and trace headers disagree on sample interval.').encode()\n", "stream.stats.textual_file_header += '{:80s}'.format('I think the header is probably right, it is 4 ms so records are 6 s.').encode()\n", "stream.stats.textual_file_header += '{:80s}'.format('Only useful lines from original file header:').encode()\n", "stream.stats.textual_file_header += '{:80s}'.format('C 2 LINE:  LINE_001           AREA                        MAP ID                ').encode()\n", "stream.stats.textual_file_header += '{:80s}'.format('C 4 INSTRUMENT: MFG            MODEL            SERIAL NO                       ').encode()\n", "stream.stats.textual_file_header += '{:80s}'.format('C 5 DATA TRACES/RECORD: 282  AUXILIARY TRACES/RECORD:  2    CDP FOLD            ').encode()\n", "stream.stats.textual_file_header += '{:80s}'.format('C 6 SAMPLE INTERNAL:  4MS     SAMPLES/TRACE: 750  BITS/IN      BYTES/SAMPLE 4   ').encode()\n", "\n", "# Binary header.\n", "stream.stats.binary_file_header = SEGYBinaryFileHeader()\n", "stream.stats.binary_file_header.trace_sorting_code = 4\n", "stream.stats.binary_file_header.seg_y_format_revision_number = 0x0100\n", "\n", "import sys\n", "stream.write('../data/poland_brute_stack.sgy', format='SEGY', data_encoding=5, byteorder=sys.byteorder)"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["## NMO velocity\n", "\n", "From Madagascar velocity scan: https://www.dropbox.com/s/alski0p047ylwu0/Screenshot%202016-09-14%2009.28.40.png?raw=1\n", "\n", "Min velocity (blue): 2200 m/s, max velocity (red): 4250 m/s"], "cell_type": "markdown", "metadata": {}}, {"source": ["import numpy as np\n", "velocity = np.load('../data/poland/Velocity.npy')\n", "plt.imshow(velocity, cmap='viridis')\n", "plt.colorbar()"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["mi, ma = np.amin(velocity), np.amax(velocity)\n", "mi, ma"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["# There are 251 gathers, and 1501 time samples\n", "# So we need this array to be 1501 rows by 251 columns."], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["from scipy.misc import imresize"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["v = imresize(velocity,(1501, 251))"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["We lost the scaling:"], "cell_type": "markdown", "metadata": {}}, {"source": ["np.amin(v), np.amax(v)"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["Let's also fix the orientation \u2014\u00a0we want traces in the first dimension."], "cell_type": "markdown", "metadata": {}}, {"source": ["v = ((v/255).T * (ma - mi) + mi).astype(np.int16)"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["np.amin(v), np.amax(v)"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["plt.plot(v[40])"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["plt.imshow(v.T, aspect=0.1)\n", "plt.colorbar()"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["stream = Stream()\n", "\n", "for i, trace in enumerate(v):\n", "\n", "    # Make the trace.\n", "    tr = Trace(trace)\n", "\n", "    # Add required data.\n", "    tr.stats.delta = 0.004\n", "    tr.stats.starttime = 0  # Not strictly required.\n", "\n", "    # Add yet more to the header (optional).\n", "    tr.stats.segy = {'trace_header': SEGYTraceHeader()}\n", "    tr.stats.segy.trace_header.trace_sequence_number_within_line = i + 1\n", "    tr.stats.segy.trace_header.receiver_group_elevation = 0\n", "\n", "    # Append the trace to the stream.\n", "    stream.append(tr)\n", "    \n", "# Text header.\n", "stream.stats = AttribDict()\n", "stream.stats.textual_file_header = '{:80s}'.format('This is the textual header.').encode()\n", "stream.stats.textual_file_header += '{:80s}'.format('This file contains velocity data.').encode()\n", "\n", "# Binary header.\n", "stream.stats.binary_file_header = SEGYBinaryFileHeader()\n", "stream.stats.binary_file_header.trace_sorting_code = 4\n", "stream.stats.binary_file_header.seg_y_format_revision_number = 0x0100\n", "\n", "# Encodings:\n", "# 1: IBM, 32-bit float\n", "# 2: 32-bit int\n", "# 3: 16-bit int\n", "# 4: obselete\n", "# 5: IEEE, 32-bit float\n", "# 8: 8-bit int\n", "stream.write('../data/poland/poland_velocity.sgy', format='SEGY', data_encoding=3, byteorder=sys.byteorder)"], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": [], "cell_type": "code", "execution_count": null, "metadata": {}, "outputs": []}, {"source": ["<hr />\n", "\n", "<div>\n", "<img src=\"https://avatars1.githubusercontent.com/u/1692321?s=50\"><p style=\"text-align:center\">\u00a9 Agile Geoscience 2016</p>\n", "</div>"], "cell_type": "markdown", "metadata": {}}]}