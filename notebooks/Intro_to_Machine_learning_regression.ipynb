{"metadata": {"language_info": {"pygments_lexer": "ipython3", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "version": "3.5.4", "file_extension": ".py", "nbconvert_exporter": "python"}, "anaconda-cloud": {}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat": 4, "cells": [{"metadata": {}, "cell_type": "markdown", "source": ["<a id='top'></a>\n", "# Log completion by ML regression"]}, {"metadata": {}, "cell_type": "markdown", "source": ["- Typical and useful Pandas\n", "    - Data exploration using Matplotlib\n", "    - Basic steps for data cleaning\n", "    - **Exercise: Find problem in specific well log data.**\n", "    - Feature engineering\n", "- Setup scikit-learn workflow\n", "    - Making X and y\n", "- Choosing a model\n", "    - Classification vs Regression\n", "- Evaluating model performance\n", "    - Parameter selection and tuning\n", "    - GridSearch\n", "- Add more data / remove data "]}, {"metadata": {}, "cell_type": "markdown", "source": ["## More Pandas\n", "---"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Load Numpy, Pandas and Matplotlib"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "\n", "% matplotlib inline"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Define the name of the file to be loaded and use Pandas to read it. Note that the name can be a PATH pointing at the file."]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["datafile = '../data/training_DataFrame.csv'"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Pandas expects by default a column on the file to be an index for each row of values. For this example, column 1 (index = 0) is that column."]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["wells = pd.read_csv(datafile, index_col=0)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["# Data Exploration and cleaning"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Before feeding our machines with data to learn from, it's important to make sure that we feed them the best possible data. Pandas has a few methods to explore the contents of the data. The `head()` method shows the top rows of the DataFrame."]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["wells.head()"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Another useful Pandas method is `describe()`, which compile useful statistics of each numeric column in the `DataFrame`. "]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["wells.describe()"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Note how the `count` row is not the same for all columns? This means that there are some values that Pandas doesn't think they are numbers! (Could be missing values or `NaN`s). There are many strategies to deal with missing data but for this excercise we're just going to ignore the rows that contain these bad values."]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["wells = wells.dropna()"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["wells.describe()"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Now every column in the `DataFrame` should contain the same number of elements and now we can focus on the statistics themselves. Look at each log property, do those `mean`, `min` and `max` look OK? `ILD` shouldn't have negative values. Let's take them out of our set:"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["wells = wells[wells.ILD > 0]"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["wells.describe()"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Another typical first approach to explore the data is to study the distribution of values in the dataset..."]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["ax = wells.hist(column=\"RHOB\", figsize=(8,6), bins=20)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["<div class=\"alert alert-success\">\n", "    <b>Exercise</b>:\n", "     <ul>\n", "      <li>\n", "      That distribution doesn't seem right. Can you exclude the `DataFrame` values for which `RHOB` is higher than `1800`?\n", "      </li>\n", "      <p>\n", "    </ul>\n", "</div>"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# Put your code here\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["<div class=\"alert alert-success\">\n", "    <b>Exercise</b>:\n", "     <ul>\n", "      <li>\n", "      Explore the rest of the `DataFrame`. Do all distributions look OK?\n", "      </li>\n", "      <p>\n", "    </ul>\n", "</div>"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Seaborn has a few tricks to display histograms better"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import seaborn as sns"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["wells.ILD.values"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["sns.distplot(wells['ILD'])"]}, {"metadata": {}, "cell_type": "markdown", "source": ["<div class=\"alert alert-success\">\n", "    <b>Exercise</b>:\n", "     <ul>\n", "      <li>\n", "      Calculate the `log` of ILD and store it in the `DataFrame`\n", "      </li>\n", "      <p>\n", "    </ul>\n", "</div>"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# Put your code here\n"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["wells = wells[wells.DPHI > 0]"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["sns.distplot(wells.DPHI)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["# Load testing data"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["w_train = wells.copy()\n", "w_test = pd.read_csv('../data/testing_DataFrame.csv', index_col=0)\n", "w_test_complete = pd.read_csv('../data/testing_DataFrame_complete.csv', index_col=0)"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["w_test.head()"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["w_test.describe()"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["w_test = w_test[w_test.DPHI > 0]"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["w_test_complete = w_test_complete[w_test_complete.DPHI > 0]"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["w_test.describe()"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Let's start testing our training pipeline with a subset of wells. We can come back to this and change the number of wells we include, to see how it affects the result."]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["w_train = w_train[w_train.well_ID < 25]"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# Make X and y\n", "X = w_train[['Depth','GR','ILD','NPHI']].as_matrix()\n", "y = w_train['RHOB'].values"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["X.shape"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Set up the testing matrix of features we want to use to predict the missing `RHOB`"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["X_test = w_test[['Depth','GR','ILD','NPHI']].as_matrix()"]}, {"metadata": {}, "cell_type": "markdown", "source": ["We will display the predicted vs. true results for a test well"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["well_id = 81"]}, {"metadata": {}, "cell_type": "markdown", "source": ["# Available scikit-learn models to choose from:\n", "\n", "http://scikit-learn.org/stable/supervised_learning.html"]}, {"metadata": {}, "cell_type": "markdown", "source": ["# Linear Regression\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["A first simple approach is to apply a linear model"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn import linear_model                \n", "\n", "# Create linear regression object\n", "regr = linear_model.LinearRegression()\n", "\n", "# Train the model using the training sets\n", "regr.fit(X,y)\n", "\n", "# Make predictions using the testing set\n", "y_test_LR = regr.predict(X_test)\n", "\n", "# add a new column to data frame that already exists\n", "w_test_complete['RHOB_pred_LinReg'] = y_test_LR\n", "\n", "my_well = w_test_complete[w_test_complete.well_ID==well_id]\n", "\n", "plt.figure(figsize=(3,10))\n", "plt.plot(my_well.RHOB, my_well.Depth, 'k')\n", "plt.plot(my_well.RHOB_pred_LinReg, my_well.Depth,'r')"]}, {"metadata": {}, "cell_type": "markdown", "source": ["<div class=\"alert alert-success\">\n", "    <b>Exercise</b>:\n", "     <ul>\n", "      <li>\n", "      Complete the following code to test the different classifiers similar to the Linear Regression case\n", "      </li>\n", "      <p>\n", "    </ul>\n", "</div>"]}, {"metadata": {}, "cell_type": "markdown", "source": ["\n", "# Decision Tree Regressor"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": []}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# add a new column to data frame that already exists and plot the results\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["# Nearest Neighbours"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn.neighbors import KNeighborsRegressor\n", "\n", "nbrs = KNeighborsRegressor()\n"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# add a new column to data frame that already exists and plot the results\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["# Gradient Boosting Ensemble Regressor"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import numpy as np\n", "from sklearn.metrics import mean_squared_error\n", "from sklearn.ensemble import GradientBoostingRegressor\n", "\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["# Evaluation Metrics"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Although it's good to see how the plots look, a more generalized way to determine how good a model is at predicting data\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["http://scikit-learn.org/stable/model_selection.html#model-selection"]}, {"metadata": {}, "cell_type": "markdown", "source": ["\"Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set X_test, y_test. Note that the word \u201cexperiment\u201d is not intended to denote academic use only, because even in commercial settings machine learning usually starts out experimentally.\""]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn.model_selection import cross_val_score\n", "\n", "scores = cross_val_score(est, X_test, w_test_complete.RHOB, cv=5, scoring='neg_mean_squared_error')\n", "scores  "]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Regression metrics"]}, {"metadata": {}, "cell_type": "markdown", "source": ["[TOP](#top)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["http://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn.metrics import explained_variance_score\n", "print(explained_variance_score(my_well.RHOB, my_well.RHOB_pred_LinReg))  \n", "print(explained_variance_score(my_well.RHOB, my_well.RHOB_pred_DTR))\n", "print(explained_variance_score(my_well.RHOB, my_well.RHOB_pred_KNN))\n"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn.metrics import mean_squared_error\n", "print(mean_squared_error(my_well.RHOB, my_well.RHOB_pred_LinReg))  \n", "print(mean_squared_error(my_well.RHOB, my_well.RHOB_pred_DTR))\n", "print(mean_squared_error(my_well.RHOB, my_well.RHOB_pred_KNN))"]}, {"metadata": {}, "cell_type": "markdown", "source": ["# Feature Engineering"]}, {"metadata": {}, "cell_type": "markdown", "source": ["What can we do to help our classifier?"]}, {"metadata": {}, "cell_type": "markdown", "source": ["<div class=\"alert alert-success\">\n", "    <b>Exercise</b>:\n", "     <ul>\n", "      <li>\n", "      Create a function using `np.convolve` to smooth a log curve and return the smoothed version to add to the `DataFrame`\n", "      </li>\n", "      <p>\n", "    </ul>\n", "</div>"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# s_NPHI will be the smoothed array!\n", "X = w_train[['Depth','GR','ILD','NPHI','s_NPHI']].as_matrix()\n", "\n"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["print(mean_squared_error(my_well.RHOB, my_well.RHOB_pred_GBT)) "]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn.metrics import mean_squared_error\n", "print(mean_squared_error(my_well.RHOB, my_well.RHOB_pred_GBT))  "]}, {"metadata": {}, "cell_type": "markdown", "source": ["<hr />\n", "\n", "<p style=\"color:gray\">\u00a92017 Agile Geoscience. Licensed CC-BY.</p>"]}], "nbformat_minor": 2}